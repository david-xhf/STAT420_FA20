---
title: 'STAT 420: Homework 10'
author: "Haofei Xu, haofeix2"
output:
  html_document:
    theme: readable
    toc: yes
---


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
# Two functions from hw09
Q_Q_plot = function(model, pointcol = "blue", linecol = "orange") {
  qqnorm(resid(model),
       col = pointcol,
       pch = 20,
       cex = 1)
  qqline(resid(model),
         col = linecol,
         lwd = 2)
}
fitted_vs_resid = function(model, pointcol = "blue", linecol = "orange") {
  plot(fitted(model), resid(model),
       col = pointcol,
       pch = 20,
       cex = 1,
       xlab = "Fitted",
       ylab = "Residuals")
  abline(h = 0, col = linecol, lwd = 2)
}
```

## Exercise 1 (TV Is Healthy?)

For this exercise we will use the `tvdoctor` data, which can be found in the `faraway` package. After loading the `faraway` package, use `?tvdoctor` to learn about this dataset.

```{r, message = FALSE, warning = FALSE}
library(faraway)
library(lmtest)
```

**(a)** Fit a simple linear regression with `life` as the response and `tv` as the predictor. Plot a scatterplot and add the fitting line. Check the assumptions of this model.
```{r}
slr_model = lm(life ~ tv, data = tvdoctor)
plot(life ~ tv, data = tvdoctor, 
     col = "blue", 
     pch = 20, 
     cex = 1)
abline(slr_model, col = "orange", lwd = 2)
```

- Check the assumption
```{r}
Q_Q_plot(slr_model)
```

It looks good. Most of the points are around the line.
```{r}
fitted_vs_resid(slr_model)
```

The residuals vs fitted graph is not good enough for the model.

**(b)** Fit higher order polynomial models of degree 3, 5, and 7. For each, plot a fitted versus residuals plot and comment on the constant variance assumption. Based on those plots, which of these three models do you think are acceptable? Use a statistical test(s) to compare the models you just chose. Based on the test, which is preferred? Check the normality assumption of this model. Identify any influential observations of this model.
```{r}
deg3 = lm(life ~ poly(tv, 3), data = tvdoctor)
fitted_vs_resid(deg3) # Degree 3
deg5 = lm(life ~ poly(tv, 5), data = tvdoctor)
fitted_vs_resid(deg5) # Degree 5
deg7 = lm(life ~ poly(tv, 7), data = tvdoctor)
fitted_vs_resid(deg7) # Degree 7
```

Degree 3 violates the assumption while they other two don't. We will compare the other two.
```{r}
anova(deg5, deg7)
```
p value is not significant, we stick with model of Degree 5 `deg5`.
```{r}
Q_Q_plot(deg5)
tvdoctor[cooks.distance(deg5) > 4 / length(cooks.distance(deg5)),]
```
QQ plot holds true on normality assumption and influential points present. 

## Exercise 2 (Brains)

The data set `mammals` from the `MASS` package contains the average body weight in kilograms $(x)$ and the average brain weight in grams $(y)$ for $62$ species of land mammals. Use `?mammals` to learn more.

```{r, message = FALSE, warning = FALSE}
library(MASS)
```

**(a)** What are the smallest and largest body weights in the dataset?
```{r}
min(mammals$body)
max(mammals$body)
```
**(b)** What are the smallest and largest brain weights in the dataset?
```{r}
min(mammals$brain)
max(mammals$brain)
```
**(c)** Plot average brain weight $(y)$ versus average body weight $(x)$.
```{r}
plot(brain ~ body, 
     data = mammals,
     main = "Brain Weight vs Body Weight",
     xlab = "Body Weight",
     ylab = "Brain Weight",
     pch  = 20,
     col  = "orange")
```

**(d)** Fit a linear model with `brain` as the response and `body` as the predictor. Test for significance of regression. Do you think this is an appropriate model?
```{r}
model = lm(brain ~ body, data = mammals)
anova(model)
```
In the anova table, it shows it's significant since p value is very small.
```{r}
fitted_vs_resid(model)
Q_Q_plot(model)
```

It's not appropriate, it violates the assumptions.

Recall, *the log rule*: if the values of a variable range over more than one order of magnitude and the variable is strictly positive, then replacing the variable by its logarithm is likely to be helpful.

**(e)** Since the body weights do range over more than one order of magnitude and are strictly positive, we will use $\log(\text{body weight})$ as our *predictor*, with no further justification. Use the Box-Cox method to verify that $\log(\text{brain weight})$ is then a "recommended" transformation of the *response* variable. That is, verify that $\lambda = 0$ is among the "recommended" values of $\lambda$ when considering,

\[
g_\lambda(y) = \beta_0 + \beta_1 \log(\text{body weight})+\epsilon
\]

Please include the relevant plot in your results, using an appropriate zoom onto the relevant values.
```{r}
model_log = lm(brain ~ log(body), data = mammals)
boxcox(model_log, lambda = seq(-0.2, 0.2, by = 0.05), plotit = TRUE)
```

The 95% Confidence interval includes $\lambda = 0$, so it is appropriate.

**(f)** Fit the model justified in part **(e)**. That is, fit a model with $\log(\text{brain weight})$ as the response and $\log(\text{body weight})$ as a predictor. Plot $\log(\text{brain weight})$ versus $\log(\text{body weight})$ and add the regression line to the plot. Does a linear relationship seem to be appropriate here?
```{r}
log_log = lm(log(brain) ~ log(body), data = mammals)
plot(log(brain) ~ log(body),
     data = mammals,
     main = "log of Brain Weight vs log of Body Weight",
     col = "orange",
     pch = 20,
     cex = 1)
abline(log_log, col = "blue", lwd = 2)
```

The linear model of log of both variables is appropriate.

**(g)** Use a Q-Q plot to check the normality of the errors for the model fit in part **(f)**.
```{r}
Q_Q_plot(log_log)
```

The normality assumption is not violated.

**(h)** Use the model from part **(f)** to predict the brain weight of a male Pikachu which, has a body weight of 13.4 pounds. (Pikachu would be mammals, right?) Construct a 99% prediction interval.
```{r}
pikachu = data.frame(body = 13.4 * 0.453592)
exp(predict(log_log, pikachu, interval = "prediction", level = 0.99))
```
The 99% prediction interval is (5.1, 211.4).

## Exercise 3 (EPA Emissions Data, Redux)

For this exercise we will again use the data stored in [`epa2015.csv`](epa2015.csv). It contains detailed descriptions of 4,411 vehicles manufactured in 2015 that were used for fuel economy testing [as performed by the Environment Protection Agency]( https://www3.epa.gov/otaq/tcldata.htm).

**(a)** Recall the model we had finished with last time:

```{r}
epa2015 = read.csv("epa2015.csv")
epa2015$type = as.factor(epa2015$type)
co2_int = lm(CO2 ~ horse * type, data = epa2015)
```

Which looked like this:

```{r}
plot(CO2 ~ horse, data = epa2015, col = type)

int_coef = summary(co2_int)$coef[,1]

int_both    = int_coef[1]
int_car     = int_coef[1] + int_coef[3]
int_truck   = int_coef[1] + int_coef[4]

slope_both  = int_coef[2]
slope_car   = int_coef[2] + int_coef[5]
slope_truck = int_coef[2] + int_coef[6]

abline(int_both, slope_both, lwd = 3, col = "black")
abline(int_car, slope_car, lwd = 3, col = "red")
abline(int_truck, slope_truck, lwd = 3, col = "green")
```

Create a fitted vs residuals plot for this model. Do you believe the constant variance assumption has been violated?
```{r}
fitted_vs_resid(co2_int)
```

The constant variance assumption has been violated.

**(b)** Fit the same model as **(a)** but with a logged response. Create a fitted vs residuals plot for this model. Compare to the previous. Do you believe the constant variance assumption has been violated? Any other assumptions?
```{r}
logged_co2 = lm(log(CO2) ~ horse * type, data = epa2015)
fitted_vs_resid(logged_co2)
```

The constant variance assumption has not been violated, while the linear assumption has been violated.

**(c)** Fit a model that has all of the terms from the model in **(b)** as well as a quadratic term for `horse`. Use `log(CO2)` as the response. Create a fitted vs residuals plot for this model. Compare to the previous. Comment on model assumptions.
```{r}
log2 = lm(log(CO2) ~ horse * type + I(horse ^ 2), data = epa2015)
fitted_vs_resid(log2)
```

The constant viariance assumption has not been violated. It's better than the previous model.

**(d)** Perform further analysis of the model fit in part **(c)**. Can you find any violations of assumptions?
```{r}
Q_Q_plot(log2)
```

The normality assumption is violated, clearly.

## Exercise 4 (Bigger Is Better?)

Consider the true model,

\[
Y = 3 - 4 x + \epsilon,
\]

where $\epsilon \sim N(\mu = 0, \sigma = 9)$.

We can simulate observations from this model. We choose a sample size of 40.

```{r}
n = 40
set.seed(114)
x = runif(n, 0 , 10)
y = 3 - 4 * x + rnorm(n, 0 , 3)
```

Consider two models, one small, one big. The small fits a SLR model. The big fits a polynomial model of degree 10.

```{r}
fit_slr = lm(y ~ x)
fit_big = lm(y ~ poly(x, 10))
```

The big model has a smaller RMSE.

```{r}
mean(resid(fit_slr) ^ 2)
mean(resid(fit_big) ^ 2)
```

However, it is not significant when compared to the small.

```{r}
anova(fit_slr, fit_big)
```

By plotting the data and adding the two models, we see the the degree 10 polynomial is *very* wiggly. 

```{r}
plot(x, y, pch = 20, cex = 2)
abline(fit_slr, col = "darkorange", lwd = 3)
lines(seq(0, 10, 0.01), 
      predict(fit_big, newdata = data.frame(x = seq(0, 10, 0.01))), 
      col = 'dodgerblue', lwd = 3) 
```

**(a)** Use the following code after changing `birthday` to your birthday.

```{r}
num_sims = 1000
rmse_slr = rep(0, num_sims)
rmse_big = rep(0, num_sims)
pval     = rep(0, num_sims)
birthday = 20000623
set.seed(birthday)
```

Repeat the above process, keeping `x` the same, then re-generating `y` and fitting the SLR and big models `1000` times. Each time, store the RMSE of each model, and the p-value for comparing the two. (In the appropriate variables defined above.)
```{r}
for (i in 1:num_sims){
  y = 3 - 4 * x + rnorm(n, 0 , 3)
  fit_slr = lm(y ~ x)
  fit_big = lm(y ~ poly(x, 10))
  rmse_slr[i] = mean(resid(fit_slr) ^ 2)
  rmse_big[i] = mean(resid(fit_big) ^ 2)
  pval[i]     = anova(fit_slr, fit_big)$"Pr(>F)"[2]
}
```

**(b)** What proportion of the RMSEs of the SLR model are smaller than the big model?
```{r}
mean(rmse_slr < rmse_big)
```
**(c)** What proportion of the p-values are less than 0.05?
```{r}
mean(pval < 0.05)
```
**(d)** Do you think bigger is better?
No, the bigger doesn't bring a better result.