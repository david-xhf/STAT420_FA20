---
title: 'STAT 420: Homework 04'
author: "Haofei Xu, haofeix2"
output:
  html_document:
    theme: readable
    toc: yes
---

## Exercise 1 (Using `lm` for Inference)

For this exercise we will again use the `faithful` dataset. Remember, this is a default dataset in `R`, so there is no need to load it. You should use `?faithful` to refresh your memory about the background of this dataset about the duration and waiting times of eruptions of [the Old Faithful geyser](http://www.yellowstonepark.com/about-old-faithful/) in [Yellowstone National Park](https://en.wikipedia.org/wiki/Yellowstone_National_Park).

**(a)** Fit the following simple linear regression model in `R`. Use the eruption duration as the response and waiting time as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `faithful_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.
```{r}
faithful_model = lm(eruptions ~ waiting, data = faithful)
summary(faithful_model)
summary(faithful_model)$coefficients[2,3:4]
```
**Null hypothesis:** $\beta_1 = 0$;\
**Alternative:** $\beta_1 \neq 0$;\
**Test statistic:** `r summary(faithful_model)$coefficients[2,3]`;\
**p-value** = $8.13\times10^{-100}$;\
**Decision:** Reject the null hypotheses since p-value is far smaller than 0.01;\
**Conclusion:** Since $\beta_1 \neq 0$, It can be concluded that there is a linear relationship between eruption duration and waiting time.

**(b)** Calculate a 99% confidence interval for $\beta_1$. Give an interpretation of the interval in the context of the problem.
```{r}
confint(faithful_model, "waiting", level = 0.99)
```
\ We are 99% confident that the mean eruption duration will increase between 0.0698727 and 0.0813832 minutes as a result of 1 minute increase in the waiting time.

**(c)** Calculate a 90% confidence interval for $\beta_0$. Give an interpretation of the interval in the context of the problem.
```{r}
confint(faithful_model, "(Intercept)", level = 0.90)
```
\ We are 90% confident that the mean eruption duration will increase between -2.13833519 and -1.60969678 minutes when the waiting time is 0.

**(d)** Use a 95% confidence interval to estimate the mean eruption duration for waiting times of 75 and 80 minutes. Which of the two intervals is wider? Why?
```{r}
wait_times = data.frame(waiting = c(75, 80))
predict(faithful_model, wait_times, interval = c("confidence"), level = 0.95)
mean(faithful$waiting)
```
\ The 95% confidence interval for 75 is (3.736159, 3.860002), for 80 is (4.104848, 4.247592)\
\ The 95% confidence interval for waiting time of 80 minutes is wider since 80 is further away from sample mean than 75 is. 

**(e)** Use a 95% prediction interval to predict the eruption duration for waiting times of 75 and 100 minutes.
```{r}
wait_times = data.frame(waiting = c(75, 100))
predict(faithful_model, wait_times, interval = c("prediction"), level = 0.95)
```
\ For waiting time of 75 minutes, we are 95% confident that the estimated eruption duration is within (2.818592, 4.777569), for waiting time of 100 minutes, the interval is (4.701239, 6.676319).

**(f)** Create a scatterplot of the data. Add the regression line, 95% confidence bands, and 95% prediction bands.
```{r}
waiting_grid = seq(min(faithful$waiting), max(faithful$waiting), by = 0.01)
duration_confint_band = predict(faithful_model, newdata = data.frame(waiting = waiting_grid), interval = "confidence", level = 0.95)
duration_pred_band = predict(faithful_model, newdata = data.frame(waiting = waiting_grid), interval = "prediction", level = 0.95)
plot(eruptions ~ waiting, data = faithful,
     xlab = "Waiting Time in minutes",
     ylab = "Eruption Length in minutes",
     main = "Eruption Length vs Waiting Time",
     pch  = 20,
     cex  = 1,
     col  = "darkorange")
abline(faithful_model, lwd = 3, col = "blue")
lines(waiting_grid, duration_confint_band[,2], col = "yellow", lwd = 3)
lines(waiting_grid, duration_confint_band[,3], col = "yellow", lwd = 3)
lines(waiting_grid, duration_pred_band[,2], col = "green", lwd = 3)
lines(waiting_grid, duration_pred_band[,3], col = "green", lwd = 3)
```

## Exercise 2 (Using `lm` for Inference)

For this exercise we will again use the `diabetes` dataset, which can be found in the `faraway` package.

**(a)** Fit the following simple linear regression model in `R`. Use the total cholesterol as the response and weight as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `cholesterol_model`. Use an $F$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The ANOVA table (You may use `anova()` and omit the row for Total.)
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.05$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.
```{r}
library(faraway)
cholesterol_model = lm(chol ~ weight, data = diabetes)
summary(cholesterol_model)
summary(cholesterol_model)$fstatistic
summary(cholesterol_model)$coefficients
knitr::kable(anova(cholesterol_model))
```
**Null hypothesis:** $\beta_1 = 0$;\
**Alternative:** $\beta_1 \neq 0$;\
**Test statistic:** `r summary(cholesterol_model)$fstatistic[1]`;\
**p-value** = `r summary(cholesterol_model)$coefficients[2, 4]`;\
**Decision:** We do not reject the null hypotheses since p-value is greater than 0.05;\
**Conclusion:** Since $\beta_1 = 0$, It can be concluded that there isn't a linear relationship between total cholesterol and weight.

**(b)** Fit the following simple linear regression model in `R`. Use HDL as the response and weight as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `hdl_model`. Use an $F$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The ANOVA table (You may use `anova()` and omit the row for Total.)
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.05$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.
```{r}
hdl_model = lm(hdl ~ weight, data = diabetes)
summary(hdl_model)
summary(hdl_model)$fstatistic
summary(hdl_model)$coefficients
knitr::kable(anova(hdl_model))
```
**Null hypothesis:** $\beta_1 = 0$;\
**Alternative:** $\beta_1 \neq 0$;\
**Test statistic:** `r summary(hdl_model)$fstatistic[1]`;\
**p-value** = $2.8905\times10^{-9}$;\
**Decision:** Reject the null hypotheses since p-value is smaller than 0.05;\
**Conclusion:** Since $\beta_1 \neq 0$, there is a linear relationship between HDL and weight.

## Exercise 3 (Inference "without" `lm`)

For this exercise we will once again use the data stored in [`goalies.csv`](goalies.csv). It contains career data for all 716 players in the history of the National Hockey League to play goaltender through the 2014-2015 season. The two variables we are interested in are:

- `W` - Wins
- `MIN` - Minutes

Fit a SLR model with `W` as the response and `MIN` as the predictor. Test $H_0: \beta_1 = 0.008$ vs $H_1: \beta_1 < 0.008$ at $\alpha = 0.01$. Report the following: 

- $\hat{\beta_1}$
- $SE[\hat{\beta_1}]$
- The value of the $t$ test statistic
- The degrees of freedom
- The p-value of the test
- A statistical decision at $\alpha = 0.01$

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

You should use `lm()` to fit the model and obtain the estimate and standard error. But then you should directly calculate the remaining values. Hint: be careful with the degrees of freedom. Think about how many observations are being used.
```{r}
goalies = read.csv("goalies.csv")
goalies_model = lm(W ~ MIN, data = goalies)
summary(goalies_model)
beta_1_hat  = summary(goalies_model)$coef[2,1]
beta_1_hat
se   = summary(goalies_model)$coef[2,2]
se
n    = length(fitted(goalies_model))
n
t    = (beta_1_hat - 0.008) / se
t
p    = pt(t, df = n - 2)
p
```
- $\hat{\beta_1}$: `r summary(goalies_model)$coef[2,1]`;\
- $SE[\hat{\beta_1}]$: $5.071\times10^{-5}$;\
- **Test statistic: ** `r (beta_1_hat - 0.008) / se`;\
- **df: ** 711;\
- **p-value: ** `r pt(t, df = n - 2)`;\
- **Decision: ** Reject the null since p-value small than 0.01

## Exercise 4 (Simulating Sampling Distributions)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = 4$
- $\beta_1 = 0.5$
- $\sigma^2 = 25$

We will use samples of size $n = 50$.

**(a)** Simulate this model $1500$ times. Each time use `lm()` to fit a SLR model, then store the value of $\hat{\beta}_0$ and $\hat{\beta}_1$. Set a seed using **your** UIN before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

```{r}
uin = 677094009
set.seed(uin)
n = 50
x = seq(0, 20, length = n)

beta_hat_0 = rep(0, 1500)
beta_hat_1 = rep(0, 1500)
for (i in 1:1500) {
  y = 4 + 0.5 * x + rnorm(n, mean = 0, sd = 5)
  beta_hat_0[i] = coef(lm(y ~ x))[1]
  beta_hat_1[i] = coef(lm(y ~ x))[2]
  }

```

**(b)** For the *known* values of $x$, what is the expected value of $\hat{\beta}_1$?

$E[\hat\beta_1] = 0.5$

**(c)** For the known values of $x$, what is the standard deviation of $\hat{\beta}_1$?
```{r}
Sxx = sum((x - mean(x)) ^ 2)
sqrt(25 / Sxx)
```
**(d)** What is the mean of your simulated values of $\hat{\beta}_1$? Does this make sense given your answer in **(b)**?
```{r}
mean(beta_hat_1)
```
\ Yes, it makes sense.

**(e)** What is the standard deviation of your simulated values of $\hat{\beta}_1$? Does this make sense given your answer in **(c)**?
```{r}
sd(beta_hat_1)
```
\ Yes, it makes sense.

**(f)** For the known values of $x$, what is the expected value of $\hat{\beta}_0$?

$E[\hat\beta_0] = 4$

**(g)** For the known values of $x$, what is the standard deviation of $\hat{\beta}_0$?
```{r}
sd_beta_hat_0 = sqrt(25 * ( 1 / n + mean(x) ^ 2 / Sxx))
sd_beta_hat_0
```
**(h)** What is the mean of your simulated values of $\hat{\beta}_0$? Does this make sense given your answer in **(f)**?
```{r}
mean(beta_hat_0)
```
\ Yes, it makes sense.

**(i)** What is the standard deviation of your simulated values of $\hat{\beta}_0$? Does this make sense given your answer in **(g)**?
```{r}
sd(beta_hat_0)
```
\ Yes, it makes sense.

**(j)** Plot a histogram of your simulated values for $\hat{\beta}_1$. Add the normal curve for the true sampling distribution of $\hat{\beta}_1$.
```{r}
hist(beta_hat_1,
     xlab = expression(hat(beta)[1]),
     breaks = 30,
     prob = TRUE)
curve(dnorm(x, mean = 0.5, sd = 0.120049), add = TRUE, lwd = 3)
```

**(k)** Plot a histogram of your simulated values for $\hat{\beta}_0$. Add the normal curve for the true sampling distribution of $\hat{\beta}_0$.
```{r}
hist(beta_hat_0,
     xlab = expression(hat(beta)[0]),
     breaks = 30,
     prob = TRUE)
curve(dnorm(x, mean = 4, sd = sd_beta_hat_0), add = TRUE, lwd = 3)
```

## Exercise 5 (Simulating Confidence Intervals)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = 1$
- $\beta_1 = 3$
- $\sigma^2 = 16$

We will use samples of size $n = 20$.

Our goal here is to use simulation to verify that the confidence intervals really do have their stated confidence level.

**(a)** Simulate this model $2000$ times. Each time use `lm()` to fit a SLR model, then store the value of $\hat{\beta}_0$ and $s_e$. Set a seed using **your** UIN before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

```{r}
uin = 677094009
set.seed(uin)
n = 20
x = seq(-5, 5, length = n)
Sxx = sum((x - mean(x)) ^ 2)
beta_hat_0 = rep(0, 2000)
se         = rep(0, 2000)
for (i in 1:2000) {
              y = 1 + 3 * x + rnorm(n, 0, sqrt(16))
  beta_hat_0[i] = coef(lm(y ~ x))[1]
          se[i] = summary((lm(y ~ x)))$sigma
  }
```

**(b)** For each of the $\hat{\beta}_0$ that you simulated calculate a 90% confidence interval. Store the lower limits in a vector `lower_90` and the upper limits in a vector `upper_90`. Some hints:

- You will need to use `qt()` to calculate the critical value, which will be the same for each interval.
- Remember that `x` is fixed, so $S_{xx}$ will be the same for each interval.
- You could, but do not need to write a `for` loop. Remember vectorized operations.
```{r}
t_90 = qt(0.950, df = n - 2)
lower_90 = beta_hat_0 - t_90 * se * sqrt(1 / n + mean(x) ^ 2 / Sxx)
upper_90 = beta_hat_0 + t_90 * se * sqrt(1 / n + mean(x) ^ 2 / Sxx)
```
**(c)** What proportion of these intervals contain the true value of $\beta_0$?
```{r}
mean(lower_90 < 1 & 1 < upper_90)
```
**(d)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_0 = 0$ vs $H_1: \beta_0 \neq 0$ at $\alpha = 0.10$?
```{r}
1 - mean(lower_90 < 0 & 0 < upper_90)
```
**(e)** For each of the $\hat{\beta}_0$ that you simulated calculate a 99% confidence interval. Store the lower limits in a vector `lower_99` and the upper limits in a vector `upper_99`.
```{r}
t_99 = qt(0.995, df = n - 2)
lower_99 = beta_hat_0 - t_99 * se * sqrt(1 / n + mean(x) ^ 2 / Sxx)
upper_99 = beta_hat_0 + t_99 * se * sqrt(1 / n + mean(x) ^ 2 / Sxx)
```
**(f)** What proportion of these intervals contain the true value of $\beta_0$?
```{r}
mean(lower_99 < 1 & 1 < upper_99)
```
**(g)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_0 = 0$ vs $H_1: \beta_0 \neq 0$ at $\alpha = 0.01$?
```{r}
1 - mean(lower_99 < 0 & 0 < upper_99)
```
