---
title: 'STAT 420: Homework 05'
author: "Fall 2020, Haofei Xu, haofeix2"
output:
  html_document:
    theme: readable
    toc: yes
---

## Exercise 1 (Using `lm`)

For this exercise we will use the data stored in [`nutrition.csv`](nutrition.csv). It contains the nutritional values per serving size for a large variety of foods as calculated by the USDA. It is a cleaned version totaling 5,138 observations and is current as of September 2015.

The variables in the dataset are:

- `ID` 
- `Desc` - Short description of food
- `Water` - in grams
- `Calories` 
- `Protein` - in grams
- `Fat` - in grams
- `Carbs` - Carbohydrates, in grams
- `Fiber` - in grams
- `Sugar` - in grams
- `Calcium` - in milligrams
- `Potassium` - in milligrams
- `Sodium` - in milligrams
- `VitaminC` - Vitamin C, in milligrams
- `Chol` - Cholesterol, in milligrams
- `Portion` - Description of standard serving size used in analysis

**(a)** Fit the following multiple linear regression model in `R`. Use `Calories` as the response and `Carbs`, `Fat`, and `Protein` as predictors.

\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \epsilon_i.
\]

Here,

- $Y_i$ is `Calories`.
- $x_{i1}$ is `Carbs`.
- $x_{i2}$ is `Fat`.
- $x_{i3}$ is `Protein`.

Use an $F$-test to test the significance of the regression. Report the following:
 
- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.
```{r}
nutrition   = read.csv("nutrition.csv")
nut_model   = lm(Calories ~ Carbs + Fat + Protein, data = nutrition)
summary(nut_model)
```
- $H_0: \beta_1 = \beta_2 = \beta_3 = 0$
- $H_1:$ Either $\beta_1$ or $\beta_2$ or $\beta_3$ $\neq 0$
- **test statistic:** $F = 1.524 \times 10^5$
- **p-value:** $0$ (p-value: $<2.2\times10^{-16}$)
- **Decision:** Reject the null hypothesis at $\alpha = 0.01$
- **Conclusion:** Since we reject the null, there is at least one parameter not equal to 0, thus there will be a linear relationship with Calories.

**(b)** Output only the estimated regression coefficients. Interpret all $\hat{\beta}_j$ coefficients in the context of the problem.
```{r}
coef(nut_model)
```
- $\hat{\beta}_0 = 3.768066$ means that when a food contains 0 Carbs, 0 Fat and 0 Protein, the estimated Calories of a food will be 3.768066.
- $\hat{\beta}_1 = 3.773605$ means that when a food increase 1g on its Carbs, it will cause an estimated increase of 3.773605 in Calories.
- $\hat{\beta}_2 = 8.804109$ means that when a food increase 1g on its Fat, it will cause an estimated increase of 8.804109 in Calories.
- $\hat{\beta}_2 = 3.967269$ means that when a food increase 1g on its Protein, it will cause an estimated increase of 3.967269 in Calories.

**(c)** Use your model to predict the amount of `Calories` in a Big Mac. According to [McDonald's publicized nutrition facts](http://nutrition.mcdonalds.com/getnutrition/nutritionfacts.pdf), the Big Mac contains 47g of carbohydrates, 28g of fat, and 25g of protein.
```{r}
predict(nut_model, newdata = data.frame(Carbs = 47, Fat = 28, Protein = 25))
```
**(d)** Calculate the standard deviation, $s_y$, for the observed values in the Calories variable. Report the value of $s_e$ from your multiple regression model. Interpret both estimates in the context of this problem.
```{r}
s_y = sd(nutrition$Calories)
s_y
s_e = summary(nut_model)$sigma
s_e
```
- $s_y = 179.2444$ means that the mean variation of Calories between the its mean is 179.2444.
- $s_e = 18.89119$ means that the mean variation of the residuals of the model is 18.89119.

**(e)** Report the value of $R^2$ for the model. Interpret its meaning in the context of the problem.
```{r}
summary(nut_model)$r.squared
```
It means 98.89% of the observed variation in Calories can be explained by our linear model.

**(f)** Calculate a 90% confidence interval for $\beta_2$. Give an interpretation of the interval in the context of the problem.
```{r}
confint(nut_model, level = 0.90)[3,]
```
**Interpretation: **We are 90% confident that mean as fat increase by 1g,  Calories will increase by between 8.778930 and 8.829288 grams.

**(g)** Calculate a 95% confidence interval for $\beta_0$. Give an interpretation of the interval in the context of the problem.
```{r}
confint(nut_model, level = 0.95)[1,]
```
**Interpretation: **We are 95% confident that the mean Calories is between 2.802779 and 4.733353g when there are no Carbs, Fat and Protein.

**(h)** Use a 99% confidence interval to estimate the mean Calorie content of a small order of McDonald's french fries that has 30g of carbohydrates, 11g of fat, and 2g of protein. Interpret the interval in context.
```{r}
predict(nut_model, newdata = data.frame(Carbs = 30, Fat = 11, Protein = 2), interval = "confidence", level = 0.99)
```
**Interpretation: **We are 99% confident that the mean Calories is between 220.8924 and 222.6195g when there are 30g Carbs, 11g Fat, and 2g Protein.

**(i)** Use a 90% prediction interval to predict the Calorie content of new healthy menu item that has 11g of carbohydrates, 1.5g of fat, and 1g of protein. Interpret the interval in context.
```{r}
predict(nut_model, newdata = data.frame(Carbs = 11, Fat = 1.5, Protein = 1), interval = "prediction", level = 0.90)
```
**Interpretation: **We are 90% confident that the mean Calories is between 61.77276 and 63.12954g when there are 11g Carbs, 1.5g Fat, and 1g Protein.

## Exercise 2 (More `lm`)

For this exercise we will again use the nutrition data. 

**(a)** Fit a model with Calories as the response and `Carbs`, `Sodium`, `Fat`, and `Protein` as predictors. Use an $F$-test to test the significance of the regression. Report the following:
 
- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem
```{r}
nut_model2 = lm(Calories ~ Carbs + Sodium + Fat + Protein, data = nutrition)
summary(nut_model2)
```
- $H_0: \beta_1 = \beta_2 = \beta_3 = \beta_4 = 0$
- $H_1:$ Either $\beta_1$ or $\beta_2$ or $\beta_3$ or $\beta_4 \neq 0$
- **test statistic:** $F = 1.144 \times 10^5$
- **p-value:** $0$ (p-value: $<2.2\times10^{-16}$)
- **Decision:** Reject the null hypothesis at $\alpha = 0.01$
- **Conclusion:** Since we reject the null, there is at least one parameter not equal to 0, thus there will be a linear relationship with Calories.

**(b)** For each of the predictors in part **(a)**, perform a $t$-test for the significance of its regression coefficient. Report the following for each:
 
- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$

**Carbs as predictors: **
```{r}
summary(nut_model2)$coef[2,] # Carbs as predictors
```
- $H_0: \beta_1 = 0$
- $H_1:$ $\beta_1\neq 0$
- **test statistic:** $t = 3.887173 \times 10^2$
- **p-value:** $0$
- **Decision:** Reject the null hypothesis at $\alpha = 0.01$

**Sodium as predictors: **
```{r}
summary(nut_model2)$coef[3,] # Sodium as predictors
```
- $H_0: \beta_2 = 0$
- $H_1:$ $\beta_2\neq 0$
- **test statistic:** $t = 1.3625794901$
- **p-value:** $0.1730748544$
- **Decision:** Fail to reject the null hypothesis at $\alpha = 0.01$

**Fat as predictors: **
```{r}
summary(nut_model2)$coef[4,] # Fat as predictors
```
- $H_0: \beta_3 = 0$
- $H_1:$ $\beta_3\neq 0$
- **test statistic:** $t = 5.7526170202 \times 10^2$
- **p-value:** $0$
- **Decision:** Reject the null hypothesis at $\alpha = 0.01$

**Protein as predictors: **
```{r}
summary(nut_model2)$coef[5,] # Protein as predictors
```
- $H_0: \beta_4 = 0$
- $H_1:$ $\beta_4\neq 0$
- **test statistic:** $t = 1.5053338477 \times 10^2$
- **p-value:** $0$
- **Decision:** Reject the null hypothesis at $\alpha = 0.01$

**(c)** Based on your results in part **(b)**, do you still prefer the model in part **(a)**, or is there instead a model with three predictors that you prefer? Briefly explain.

**Result: **I prefer use the model in part **(a)** since in part **(b)**, we found that we fail to reject the null hypothesis for Sodium, that means, it isn't related to the linear relationship of the model. 

## Exercise 3 (Comparing Models)

For this exercise we will use the data stored in [`goalies_cleaned.csv`](goalies_cleaned.csv). It contains career data for 462 players in the National Hockey League who played goaltender at some point up to and including the 2014 - 2015 season. The variables in the dataset are:
 
- `W` - Wins
- `GA` - Goals Against
- `SA` - Shots Against
- `SV` - Saves
- `SV_PCT` - Save Percentage
- `GAA` - Goals Against Average
- `SO` - Shutouts
- `MIN` - Minutes
- `PIM` - Penalties in Minutes
 
**(a)** Fit a multiple linear regression model with Wins as the response and all other variables as the predictors.
 
Use an $F$-test to test the significance of the regression. Report the following:
 
- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.10$
- A conclusion in the context of the problem
 
When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.
```{r}
goalies_cleaned = read.csv("goalies_cleaned.csv")
goalies_model  = lm(W ~ ., data = goalies_cleaned)
summary(goalies_model)
```
- $H_0: \beta_1 = \beta_2 = \beta_3 = \beta_4 = \beta_5 = \beta_6 = \beta_7 = \beta_8 = 0$
- $H_1:$ At least one of variables in $\beta_1$ to $\beta_8 \neq 0$
- **test statistic:** $F = 3.938 \times 10^3$
- **p-value:** $0$ (p-value: $<2.2\times10^{-16}$)
- **Decision:** Reject the null hypothesis at $\alpha = 0.10$
- **Conclusion:** Since we reject the null, there is at least one parameter not equal to 0, thus there will be a linear relationship with Wins

**(b)** Calculate the RMSE of this full model. Report the residual standard error of this full model. What is the relationship of these two values?

Recall, we have defined RMSE as,

\[
RMSE = \sqrt{\frac{1}{n} \sum_{i = 1}^{n}(y_i - \hat{y}_i)^2}.
\]
```{r}
rmse = sqrt(mean(resid(goalies_model) ^ 2))
rmse
rse  = summary(goalies_model)$sigma
rse
```
**Relationship: ** Instead of divided by $n$, RSE is using degree of freedom into calculation, which is unbiased.

**(c)** Fit a model with Wins as the response and with Goals Against, Goals Against Average, Saves, and Save Percentage as the predictors. Calculate the RMSE of this model.
```{r}
goalies_model_c = lm(W ~ GA + GAA + SV + SV_PCT, data = goalies_cleaned)
rmse = sqrt(mean(resid(goalies_model_c) ^ 2))
rmse
```
**(d)** Fit a model with Wins as the response and with Goals Against Average and Save Percentage as the predictors. Calculate the RMSE of this model.
```{r}
goalies_model_d = lm(W ~ GAA + SV_PCT, data = goalies_cleaned)
rmse = sqrt(mean(resid(goalies_model_d) ^ 2))
rmse
```
**(e)** Based on the previous three models, which model is most helpful for predicting wins? Briefly explain.

**Explanation: ** Based on the three models above, the first one with all predictors has the least RMSE which is the best prediction.

**(f)** Conduct an ANOVA $F$-test comparing the models in parts **(c)** and **(d)**. Report the following:
 
- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.10$
- A conclusion in the context of the problem
 
When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.
```{r}
anova(goalies_model_d, goalies_model_c)
```
- $H_0: \beta_{GA} = \beta_{SV} = 0$
- $H_1:$ Either $\beta_{GA}$ or $\beta_{SV} \neq 0$
- **test statistic:** $F = 3.5998 \times 10^3$
- **p-value:** $0$ (p-value: $<2.2\times10^{-16}$)
- **Decision:** Reject the null hypothesis at $\alpha = 0.10$
- **Conclusion:** The model of part **(c)** is better since we found that either $\beta_{GA}$ or $\beta_{SV} \neq 0$. That means Saves and Goals Against are useful when we predicts Wins.

## Exercise 4 (Regression without `lm`)

For this exercise use the `prostate` dataset from the `faraway` package. Use `?prosate` to learn about the dataset. The goal of this exercise is to fit a model with `lpsa` as the response and the remaining variables as predictors.

**(a)** Obtain the estimated regression coefficients **without** the use of `lm()` or any other built-in functions for regression. That is, you should use only matrix operations. Store the results in a vector `beta_hat_no_lm`. To ensure this is a vector, you may need to use `as.vector()`. Return this vector as well as the results of `sum(beta_hat_no_lm)`.
```{r}
library(faraway)
row = nrow(prostate)
col = ncol(prostate)
X = as.matrix(cbind(rep(1, row), prostate[, -col]))
y = prostate$lpsa
beta_hat_no_lm = as.vector(solve(t(X) %*% X) %*% t(X) %*% y)
beta_hat_no_lm
sum(beta_hat_no_lm)
```
**(b)** Obtain the estimated regression coefficients **with** the use of `lm()`. Store the results in a vector `beta_hat_lm`. To ensure this is a vector, you may need to use `as.vector()`. Return this vector as well as the results of `sum(beta_hat_lm)`.
```{r}
prostate_model = lm(lpsa ~ ., data = prostate)
beta_hat_lm = as.vector(coef(prostate_model))
beta_hat_lm
sum(beta_hat_lm)
```
**(c)** Use the `all.equal()` function to verify that the results are the same. You may need to remove the names of one of the vectors. The `as.vector()` function will do this as a side effect, or you can directly use `unname()`.
```{r}
all.equal(beta_hat_lm, beta_hat_no_lm)
```
**(d)** Calculate $s_e$ without the use of `lm()`. That is, continue with your results from **(a)** and perform additional matrix operations to obtain the result. Output this result. Also, verify that this result is the same as the result obtained from `lm()`.
```{r}
p     = length(beta_hat_no_lm)
y_hat = X %*% solve(t(X) %*% X) %*% t(X) %*% y
e     = y - y_hat
s_e   = as.vector((sqrt(t(e) %*% e / (row - p))))
s_e
all.equal(s_e, summary(prostate_model)$sigma)
```
**(e)** Calculate $R^2$ without the use of `lm()`. That is, continue with your results from **(a)** and **(d)** and perform additional operations to obtain the result. Output this result. Also, verify that this result is the same as the result obtained from `lm()`.
```{r}
SST   = sum((y - mean(y)) ^ 2)
SSReg = sum((y_hat - mean(y)) ^ 2)
R2    = SSReg / SST
R2
all.equal(R2, summary(prostate_model)$r.squared)
```
